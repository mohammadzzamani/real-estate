To select random messages from each month

select id, cnty from ( select id, cnty, CASE WHEN @cnty != cnty THEN @rn := 1 ELSE @rn := @rn + 1 END rn,@cnty:=cnty FROM (select * FROM msgs_2011_11 ORDER BY RAND()) a, (select @rn := 0, @name:= NULL) r ORDER BY cnty) s WHERE rn > 2 and rn < 20  limit 20

update NLP_test_data set month_id = TIMESTAMPDIFF(MONTH, '2011-11-07', date(created_time));

./dlatkInterface.py -d mztwitter -t NLP_test_data -c cnty_month --add_ngrams -n 1 2 3 --feat_occ_filter --set_p_occ 0.01 --combine_feat_tables 1to3gram --group_freq_thresh 10000

 update NLP_test_data set cnty_month = CONCAT(cnty,'_',month_id);

show create table NLP_train_data; - To get table index details

alter table NLP_train_data drop index cnty; - to drop the index

 alter table NLP_test_data add index(cnty, month_id);

python dlatkInterface.py -d mztwitter -t NLP_train_data -c cnty_month -f 'feat$1to3gram$NLP_train_data$cnty_month$16to16$0_01' 'feat$1to3gram$NLP_train_data$cnty_month$16to1$0_01' 'feat$cat_met_a30_2000_cp_w$NLP_train_data$cnty_month$16to16' --group_freq_thresh 200 --outcome_table housing_outcomes --outcomes saf --train_regression --model ridgecv --save_model --picklefile pickles/PCA.pickle

# Adding saf labels to train features
update NLP_train_features JOIN housing_outcomes ON NLP_train_features.cnty_month = housing_outcomes.cnty_month set NLP_train_features.saf = housing_outcomes.saf;

# Wrong query used for getting month and cnty col
create table NLP_train_features_saf_temp as select NLP_train_features_saf.*, NLP_train_data.cnty, NLP_train_data.month_id from NLP_train_features_saf left join NLP_train_data on NLP_train_data.cnty_month = NLP_train_features_saf.cnty_month;


alter table NLP_test_features_saf add column cnty varchar(20);
alter table NLP_test_features_saf add column month int;

update NLP_test_features_saf set month=cast(SUBSTRING_INDEX(cnty_month, '_', -1) as unsigned);
update NLP_test_features_saf set cnty=SUBSTRING_INDEX(cnty_month, '_', 1);

# To merge tables
 create table NLP_features_ip like NLP_train_features_ip;
insert ignore into NLP_features_saf select * from NLP_test_features_saf;

# Queries to add labels to feature tables.
alter table NLP_features_ip add column ip float default NULL;
update NLP_features_ip t join housing_outcomes s on t.cnty_month = s.cnty_month update t.ip = s.ip;




# IN ORDER:

scripts/pre_process.py

alter table NLP_test add column month_id int;
alter table NLP_train add column month_id int;

update NLP_test  set month_id = TIMESTAMPDIFF(MONTH, '2011-11-07', date(created_time));
update NLP_train  set month_id = TIMESTAMPDIFF(MONTH, '2011-11-07', date(created_time));


alter table NLP_test add column cnty_month varchar(15);
alter table NLP_train add column cnty_month varchar(15);

update NLP_test set cnty_month = CONCAT(cnty,'_',month_id);
update NLP_train set cnty_month = CONCAT(cnty,'_',month_id);


alter table NLP_test add index (cnty_month);
alter table NLP_train add index (cnty_month);

alter table NLP_test add index (cnty);
alter table NLP_train add index (cnty);

To check threshold : 
select count(*) from (select count(*) as l from NLP_train group by cnty_month order by l desc) as t where l > 5000;

./dlatkInterface.py -d mztwitter -t NLP_test_data_bigger -c cnty_month --add_ngrams -n 1 2 3 --feat_occ_filter --set_p_occ 0.01 --combine_feat_tables 1to3gram --group_freq_thresh 400

./dlatkInterface.py -d mztwitter -t NLP_train_data_bigger -c cnty_month --add_ngrams -n 1 2 3 --feat_occ_filter --set_p_occ 0.01 --combine_feat_tables 1to3gram --group_freq_thresh 400

# Incase we need to just combibe :
./dlatkInterface.py -d mztwitter -t new_train -c cnty_month -f 'feat$1gram$new_train$cnty_month$16to16' 'feat$2gram$new_train$cnty_month$16to16' 'feat$1gram$new_train$cnty_month$16to16' --feat_occ_filter --set_p_occ 0.01 --combine_feat_tables 1to3gram --group_freq_thresh 400



./dlatkInterface.py -d mztwitter -t NLP_test_data_bigger -c cnty_month --add_lex_table -l met_a30_2000_cp --weighted_lexicon
./dlatkInterface.py -d mztwitter -t NLP_train_data_bigger -c cnty_month --add_lex_table -l met_a30_2000_cp --weighted_lexicon


python dlatkInterface.py -d mztwitter -t NLP_test_data_bigger -c cnty_month -f 'feat$1to3gram$NLP_test_data$cnty_month$16to16$0_01'  'feat$cat_met_a30_2000_cp_w$NLP_test_data$cnty_month$16to16' --group_freq_thresh 500 --outcome_table housing_outcomes --outcomes msp --predict_regression  --load_model --picklefile pickles/PCA_MSP.pickle
python dlatkInterface.py -d mztwitter -t NLP_train_data_bigger -c cnty_month -f 'feat$1to3gram$NLP_train_data$cnty_month$16to16$0_01'  'feat$cat_met_a30_2000_cp_w$NLP_train_data$cnty_month$16to16' --group_freq_thresh 500 --outcome_table housing_outcomes --outcomes msp --train_regression --model ridgecv --save_model --picklefile pickles/PCA_MSP.pickle
